apiVersion: v1
kind: Service
metadata:
  name: client-node-port
# What sub-type of Service object is this
spec:
  type: NodePort
  # All the ports that need to be opened up on the target object
  ports:
    # port opens up the defined port so that if any other container wants to connect to our client-pod (component: web ??) it can do so via this port
  - port: 3050
    # port inside of the target pod that we want to open up traffic to (should match containerPort from Pod definition)
    targetPort: 3000
    # port accessed by browser to test out container running inside target pod (30000 - 32767); Randomly assigned if not defined; That's why not used in Prod ??
    nodePort: 31515
  # label-selector system (relationship) is used to link the container running in the pod to the NodePort that is going to handle the (forward the req) req to the pod
  # whom am I going to forward this traffic to? To any Pod or object that has `component: web`
  selector:
    component: web

# Command run: `kubectl apply -f client-pod.yml`, `kubectl apply -f client-node-port.yml`
  ##`apply`: change the current configuration (state: deployment as a function of configuration state) of the cluster with what is in the file (-f) I am supplying you
    ### When this command is run `kubectl` talks to kubernetes control plane (Talks to the kube-apiserver that inturn talks to the kube-scheduler)
    # that instructs the container runtime running inside the kubernetes node (VM) to spin up a container (details of which are in the config file),
    # the conatiner runtime checks its image cache, if the image is there it spins up the container or it fetches from the registry (Docker Hub or yourRegistry).

    ### The Master (control plane??) adds details like how many containers are to be run in a pod, how many pods are to be run etc. to `etcd`
        # master uses this information to poll the nodes to check all the pods and services defined match what is there in `etcd`, any descrepancy like a container has died etc. triggers an update of `etcd` items (how mayn containers SHOULD be running and how many ARE running)
        # the master then isntructs conatiner runtime to spin up conatiner that has died and `etcd` gets updated and peace is restored

# Command run: `kubectl get pods`
# Prints out the status of group of object types (Pods in this case)

# Command run: `kubectl get services`
# Prints out the status of group of object types (Services in this case)

# When we try to access `localhost:31515`, nothing since it is not bound to locahost or 0.0.0.0 but to the IP of the VM (Kubernetes Node) that was created by minikube (minikube ip: to find the ip)!

# Command Run: kubectl describe pods client-pod (kubectl describe <objectType(pods, services etc.)> <name(optional; name of the particular object ex: client-pod)>)
  ## Gives details about the objectType (all if exact name not specified)
  ## Why use this: to figure out what pod (objectType) is running what image or why a pod restarted

# Limitations to declarative deployment updates:
  ## On changing the containerPort of the client-pod in the client-pod.yml file and running kubectl apply client-pod.yml, we get
    # this: `The Pod "client-pod" is invalid: spec: Forbidden: pod updates may not change fields other than `spec.containers[*].image`, `spec.initContainers[*].image`, `spec.activeDeadlineSeconds` or `spec.tolerations` (only additions to existing tolerations)`
    # which means we can onmlky update the shown properties for a pod

  ## Solution: Deployment object
    # Maintains a set of identical pods, ensuring they have correct config and the right number of them

# Pods vs Deployments:
  ## Runs a single set of tightly coupled containers vs Runs a set of identical pods
  ## Good for one-off dev purposes vs Monitors state of each pod, updating as necessary
  ## Rarely used in production vs Good for dev and production

  ## Every deployment has a Pod Template associated with it which tells the deployment the details of the pod

  # Command Run: kubectl delete -f client-pod.yml (Imperative udpate)

  # Command Run: minkube ip (ip of the VM created by minikube)